{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">MIS 285N: Big Data and Distributed Programming</p>\n",
    "# <p style=\"text-align: center;\">Project - 1 : Apache Spark</p>\n",
    "## <p style=\"text-align: center;\">Instructor: Dr. Ramesh Yerraballi</p>\n",
    "## <p style=\"text-align: center;\">Due: Monday, September 21st submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**.   \n",
    "\n",
    "Also, please make sure your code runs in your notebook before submitting.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "This project is based on Map-Reduce Framework. In these you will get to work with Spark and will get to know how \n",
    "does spark work, what functionalities does spark provide, what does map-reduce framework do and why is it useful. \n",
    "\n",
    "In this project you will be implementing a basic song recommender system. You will be given a dataset where there are multiple csv files. These csv files have data corresponding to song play count and song information.\n",
    "\n",
    "The data you would be using will be provided in a zip file along with this notebook. The __msd.zip__ archive contains:\n",
    "1. **'kaggle_visible_evaluation_triplets.txt'**. We will be using the visible part of the testing data to understand the working on Apache Spark.  The user's listening history is provided as: (user, song, play count).  \n",
    "2. In **'kaggle_songs.txt'** file, each song is marked using an index for easier representation of songs.  \n",
    "3. And **'kaggle_users.txt'** file is the canonical list of user identifiers.\n",
    "4. Take **'MSDChallengeGettingstarted.pdf'** as your reference.\n",
    "\n",
    "\n",
    "\n",
    "### **What to turn in?**  \n",
    "\n",
    "A zip folder which will have:\n",
    "1. Jupyter Notebook\n",
    "2. A brief report in PDF format on what features you used for recommendation. And a brief explanation of flow of your code. For example,  what RDD does what or, why it was created.\n",
    "3. datasets folder with the csv files you are using in your notebook.\n",
    "4. Notebook should use relative path to the csv files in datasets folder.\n",
    "5. Name of the zip folder - <your\\_name>\\_<your\\_partner_name>.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project consists of 4 questions:  \n",
    "\n",
    "1. Create an RDD with _kaggle_visible_evaluation_triplets.txt_ and replace the song name with the song index from _kaggle_songs.txt_. Identify the number of songs that do not have any rating. \n",
    "2. Generate song ratings based on the song play count as a normalized score between 0 and 1. \n",
    "3. Identify the popular song based on this rating and recommend songs to user, given user id based on the algorithm used in Movie recommender system from class. \n",
    "4. Using Cosine similarity function, identify pair-wise similarity between each pair of users and generate the top 5 most similar users without an overlap in users. \n",
    "\n",
    "The above list is the higer level idea about the questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starter code ####\n",
    "import findspark\n",
    "findspark.init('/Users/Gautam/apachespark')\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Songs\")\n",
    "sc = SparkContext(conf = conf)\n",
    "#### These lines are to tell jupyter where to find Apache Spark ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read triplet file into RDD\n",
    "triplet_rdd = sc.textFile(r\"kaggle_visible_evaluation_triplets.txt\") \\\n",
    "    .map(lambda line: line.split(\"\\t\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: \n",
    "Replace song name with song index and identify the number of songs without user history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOBONKR12A58A7A7E0', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOEGIYH12A6D4FC0E3', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOFLJQZ12A6D4FADA6', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOHTKMO12AB01843B0', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SODQZCY12A6D4F9D11', '1']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplet_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SOAAADD12AB018A9DD', '1'],\n",
       " ['SOAAADE12A6D4F80CC', '2'],\n",
       " ['SOAAADF12A8C13DF62', '3'],\n",
       " ['SOAAADZ12A8C1334FB', '4'],\n",
       " ['SOAAAFI12A6D4F9C66', '5']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_rdd = sc.textFile(r\"kaggle_songs.txt\") \\\n",
    "    .map(lambda line: line.split(\" \"))\n",
    "songs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOAAADD12AB018A9DD', '1'),\n",
       " ('SOAAADE12A6D4F80CC', '2'),\n",
       " ('SOAAADF12A8C13DF62', '3'),\n",
       " ('SOAAADZ12A8C1334FB', '4'),\n",
       " ('SOAAAFI12A6D4F9C66', '5')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we are mapping the songs_rdd dataset columns to a key-value pair.In which key is song Name \n",
    "# and value is Song Index.\n",
    "songs = songs_rdd.map(lambda z: ((z[0]),(z[1])))\n",
    "songs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOBONKR12A58A7A7E0', ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '1')),\n",
       " ('SOEGIYH12A6D4FC0E3', ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '1')),\n",
       " ('SOFLJQZ12A6D4FADA6', ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '1')),\n",
       " ('SOHTKMO12AB01843B0', ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '1')),\n",
       " ('SODQZCY12A6D4F9D11', ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '1'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we are considering the triplet_rdd and mapping it to form a key-value pair.In which Song Name is the key\n",
    "# and values are user name ,number of times the song is played. \n",
    "#We are storing it in temp. \n",
    "temp = triplet_rdd.map(lambda z: ((z[1]),(z[0],z[2])))\n",
    "temp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', '25150', '1'),\n",
       " ('c34670d9c1718361feb93068a853cead3c95b76a', '25150', '1'),\n",
       " ('c5006d9f41f68ccccbf5ee29212b6af494110c5e', '25150', '1'),\n",
       " ('e4332e11f4df6dd26673bb6b085e9a2bbdc9b8a5', '25150', '2'),\n",
       " ('baf2fe5885ab93fbbdb7fecc6691788e70afb6c8', '25150', '4'),\n",
       " ('f6e34f0a68d5ea1344511e33486f956de361db78', '25150', '1'),\n",
       " ('e326c4b9fe3659ec1dc3af53fd7e0893809dafbc', '25150', '25'),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf', '25150', '5'),\n",
       " ('daa9e7e53ae787ab4f1b5518b695198947d821a2', '25150', '1'),\n",
       " ('cd4321d8fd42ba44996e7f34c2f6404cf5884696', '25150', '1')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we are joining 'songs'rdd and 'temp' RDD.\n",
    "### We are rearranging the resultand saved it in final_triplet_rdd.\n",
    "final = temp.join(songs)\n",
    "final_triplet_rdd = final.map(lambda z: (z[1][0][0],z[1][1],z[1][0][1]))\n",
    "final_triplet_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Identifying the number of songs without user history. for which we need to find all the songs which are \n",
    "#present in the 'kaggle_songs.txt' and not present in the 'kaggle_visible_evaluation_triplets.txt' \n",
    "#we have taken the Song Name column both 'triplet_rdd' and 'songs_rdd' RDD. \n",
    "\n",
    "songs_users = triplet_rdd.map(lambda z: z[1])\n",
    "songs_total = songs_rdd.map(lambda z: z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of songs without user history: 223007\n"
     ]
    }
   ],
   "source": [
    "# As multiple users have listened to the same song.So, we are finding all the unique songs from the 'songs_users'. \n",
    "#Then subtracting the unique 'songs_users' form 'songs_total' RDD to obtain total number of songs \n",
    "#which doent have any user history.we are using the count function to get the total number of songs\n",
    "#without user history\n",
    " \n",
    "songs_users=songs_users.distinct()\n",
    "songs_without_userhistory = songs_total.subtract(songs_users).count()\n",
    "print(\"The number of songs without user history: \" +str(songs_without_userhistory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "Generate song ratings based on the play_count. For example, if (song_1, 5; song_2, 10; song_3, 5) i.e., song_1 is played 5 times, song_2 is played 10 times and song_3 is played 5 times, the normalized rating score should be 0.25, 0.5 and 0.25 respectively. \n",
    "Similarly, generate the rating for all the songs. You may notice that based on all songs, the rating is almost always very low. So, think of the best way to convert song count to ratings. (Hint: Try generating ratings based on each user's song play history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we are getting the song name and no of times songs playes from triplet_rdd,then by using reduceByKey\n",
    "# added the number of times each song is played by all the users and saved it in 'temp'\n",
    "songs_played = triplet_rdd.map(lambda z: (z[1],int(z[2])))\n",
    "temp = songs_played.reduceByKey(lambda a, v: a + v)\n",
    "### We are calculating the total sum of all songs ever played\n",
    "total = temp.map(lambda z: int(z[1])).reduce(lambda a,v:int(a)+int(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOBONKR12A58A7A7E0', 766.2066370552338),\n",
       " ('SOAUWYT12A81C206F1', 717.4861709995373),\n",
       " ('SOSXLTC12AF72A7F54', 526.7562506217104),\n",
       " ('SOFRQTD12A81C233C0', 420.68706020751074),\n",
       " ('SOEGIYH12A6D4FC0E3', 370.1068693045927),\n",
       " ('SOAXGDH12A8C13F8A1', 308.7791987613368),\n",
       " ('SONYKOW12AB01849C9', 267.97337566009423),\n",
       " ('SOVDSJC12A58A7A271', 251.06285437489456),\n",
       " ('SOUFTBI12AB0183F65', 233.4170930338167),\n",
       " ('SOHTKMO12AB01843B0', 227.38379963410995)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are calculating the rating by dividing the no of times a song is played with the total\n",
    "#no of times and saved it in the 'songs_rating' RDD. In order to scale the rating it is multiplies by 100000.\n",
    "songs_rating = temp.map(lambda z: (z[0],(int(z[1])/total)*100000)).sortBy(lambda z: -z[1])\n",
    "songs_rating.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('090b841eaf56d343a26625c2c6d08b823927bc4f', 1305),\n",
       " ('938c2632d43eeadb8a83a7cc254d014f9cea6afe', 1267),\n",
       " ('1c5aa998482a40abfd020759e7d757eb6c510e72', 1200),\n",
       " ('c6150292374fb1dad89982367b3245dd5004c718', 1192),\n",
       " ('5a9375e46a7e9b869058c7bc0e820e00d77f3e0b', 1184),\n",
       " ('d1d845a92cd34456423e781512bdb502ca385b51', 1180),\n",
       " ('957440a77858369fb7a6bcc6fa408fc187d5bd7b', 1150),\n",
       " ('315103a41c2ced1143de0c2ba20de224800e6d89', 1148),\n",
       " ('22bb29714137fa47083963c30e1a26f1bf517e7d', 1141),\n",
       " ('bda891a59a96252cc0f5b1f63f2630692b490e37', 1140)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we are calculating the ratings based on each users songs played history. For that we are calculating the \n",
    "#total number of times a user has heard all his songs by taking 'User Name' and 'Number of Times played' columns \n",
    "#from the triplet_rdd,applying reduceByKey and sorting it in descending order. Now we obtain total number of times \n",
    "#a user has heard all his songs\n",
    "user_played_songs = triplet_rdd.map(lambda z: (z[0],int(z[2])))\n",
    "total = user_played_songs.reduceByKey(lambda x, y: int(x)+int(y)).sortBy(lambda x:-x[1])\n",
    "total.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOUVUHC12A67020E3B', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOUQERE12A58A75633', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOIPJAX12A8C141A2D', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOEFCDJ12AB0185FA0', '2'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOATCSU12A8C13393A', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOZPZGN12A8C135B45', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOPFVWP12A6D4FC636', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOHEKND12A8AE481D0', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SOPSVVG12A8C13B444', '1'), 17)),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  (('SODSKZZ12AB0188524', '1'), 17))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rearranging the triplet_rdd as a key value pair in 'temp_triplet_rdd'then joining it with 'total' RDD.\n",
    "#we get 4 columns i.e user name, song name, no of times the songs played and  UsersTotal\n",
    "temp_triplet_rdd = triplet_rdd.map(lambda z: (z[0],(z[1],z[2])))\n",
    "temp = temp_triplet_rdd.join(total)\n",
    "temp.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOUVUHC12A67020E3B',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOUQERE12A58A75633',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOIPJAX12A8C141A2D',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOEFCDJ12AB0185FA0',\n",
       "  11.76470588235294),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOATCSU12A8C13393A',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOZPZGN12A8C135B45',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOPFVWP12A6D4FC636',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOHEKND12A8AE481D0',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOPSVVG12A8C13B444',\n",
       "  5.88235294117647),\n",
       " ('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SODSKZZ12AB0188524',\n",
       "  5.88235294117647)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we want to obtain ratings per song per user.So, we are dividing no of times each song is played \n",
    "#by the total number of times a user has heard his songs. \n",
    "\n",
    "rating = temp.map(lambda z: (z[0],z[1][0][0],(int(z[1][0][1])/z[1][1])*100))\n",
    "rating.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "For a given user_id (choose one by yourselves), rating, recommend 5 other songs from the list. One way to do this is based on another user who liked the same song liked by this user with rating more than the given rating and recommend the 5 songs based on the matched user's rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, we are considering the user_id,song_id. \n",
    "\n",
    "user_id=\"f6e34f0a68d5ea1344511e33486f956de361db78\"\n",
    "song_id=\"SOMDBJK12A6D4F873A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User played total no of songs:  4624340 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We are doing step 2, to get rating as we need recommandation for songs which got higher rating by other users \n",
    "#that liked the same song. 'Total' contains total no of songs played by all the users.\n",
    "\n",
    "songs_played_total = triplet_rdd.map(lambda z: (z[1],int(z[2]))).reduceByKey(lambda a, v: a + v)\n",
    "total = songs_played_total.map(lambda z: int(z[1])).reduce(lambda a,v:int(a)+int(v))\n",
    "print(\"\\nUser played total no of songs: \",total,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d',\n",
       "  'SOBONKR12A58A7A7E0',\n",
       "  0.021624707525830716),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d',\n",
       "  'SOEGIYH12A6D4FC0E3',\n",
       "  0.021624707525830716),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d',\n",
       "  'SOFLJQZ12A6D4FADA6',\n",
       "  0.021624707525830716),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d',\n",
       "  'SOHTKMO12AB01843B0',\n",
       "  0.021624707525830716),\n",
       " ('fd50c4007b68a3737fe052d5a4f78ce8aa117f3d',\n",
       "  'SODQZCY12A6D4F9D11',\n",
       "  0.021624707525830716)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Like step 2 , Now we are calculating the rating given by a specific user to a specific song and stored it in result.\n",
    "#Result contains user name, song, rating columns\n",
    "result = triplet_rdd.map(lambda x: (x[0],x[1],(int(x[2])/total)*100000))\n",
    "result.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The song rating for the given User Name and Song Name is:  0.10812353762915357\n"
     ]
    }
   ],
   "source": [
    "#We are filtering  the 'rating' rdd to obtain a row in which Song Name = given Song Name and \n",
    "#User Name = given user_id and converting the value into a float number.\n",
    "x=result.filter(lambda z: (z[0]==user_id and z[1]==song_id)).map(lambda z: z[2])\n",
    "num=float(x.collect()[0])\n",
    "print(\"\\nThe song rating for the given User Name and Song Name is: \",num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f26dd0f6f3831009dc603c0f8a78be5cfdda08d4', 0.1297482451549843),\n",
       " ('ac161501199a1b984f8deff58ef592b9ebf67483', 0.8433635935073978),\n",
       " ('c87a0f11929453f3fb3c75ee26d24183901602b1', 0.151372952680815),\n",
       " ('38184d13862f7466d8318557b921e91720fdef40', 0.1297482451549843),\n",
       " ('7c78aa227e6cf1db5dd944225079cb4ed9ce5b44', 0.151372952680815)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when User Name != given user_id AND Song Name == given song name AND Rating of Songs > Rating given by User we \n",
    "#are filtering the records from rating rdd.The resultant records are the users that have rated \n",
    "#the same song higher than the given User and re-arranging it.\n",
    "\n",
    "users=result.filter(lambda z: (z[0]!=user_id and z[1]==song_id and float(z[2])>num)).map(lambda z: (z[0],(z[2])))\n",
    "users.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('38184d13862f7466d8318557b921e91720fdef40',\n",
       "  (('SOTIYYT12AC9072CA7', 0.08649883010332286), 0.1297482451549843)),\n",
       " ('38184d13862f7466d8318557b921e91720fdef40',\n",
       "  (('SORAOUS12A8C13950A', 0.06487412257749214), 0.1297482451549843)),\n",
       " ('38184d13862f7466d8318557b921e91720fdef40',\n",
       "  (('SORHKKL12AC9072CB6', 0.08649883010332286), 0.1297482451549843)),\n",
       " ('38184d13862f7466d8318557b921e91720fdef40',\n",
       "  (('SOMDBJK12A6D4F873A', 0.1297482451549843), 0.1297482451549843)),\n",
       " ('38184d13862f7466d8318557b921e91720fdef40',\n",
       "  (('SOTIGPL12AC9072CBB', 0.08649883010332286), 0.1297482451549843))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we need to obtain all other songs heard by these Users.We are re-arranging the rating in K,V pairs and\n",
    "#joining final rdd and similar rdd. we now got all songs heard by the selected Users that like our song\n",
    "final=result.map(lambda z: (z[0],(z[1],z[2])))\n",
    "r=final.join(users)\n",
    "r.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOHTKMO12AB01843B0', 1.059610668765705),\n",
       " ('SOSUIAK12AB01850CB', 0.6487412257749214),\n",
       " ('SOPLDTD12AB0184B2F', 0.4108694429907836),\n",
       " ('SOLGPOU12A58A7EA20', 0.36762002793912213),\n",
       " ('SOWFGOB12A58A7A7FD', 0.34599532041329145)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally,we need to get the Songs heard by these Users which have rating higher than our Song.\n",
    "#All the songs with a higher rating than our song rating will be filtered and are mapped to extract \n",
    "#only the recommended Song Name and its rating and sorted in Descending order\n",
    "#by rating in order to obtain the the highest recommendations for given User.\n",
    "\n",
    "r.filter(lambda z: (z[1][0][1]>z[1][1])).map(lambda z: (z[1][0][0],z[1][0][1])).takeOrdered(5,key=lambda z:-z[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \n",
    "1. Compute cosine similarity between all pairs of users. \n",
    "2. Sort the similarity score and print the top-5 similar users. \n",
    "3. If the top-5 user set has an user appearing more than once, ignore that pair and take the next best pair from the sorted list. \n",
    "4. For a given user_id, identify the top-5 similar users and hence song recommendations from other user's list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOBONKR12A58A7A7E0', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOEGIYH12A6D4FC0E3', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOFLJQZ12A6D4FADA6', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOHTKMO12AB01843B0', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SODQZCY12A6D4F9D11', '1'],\n",
       " ['fd50c4007b68a3737fe052d5a4f78ce8aa117f3d', 'SOXLOQG12AF72A2D55', '1'],\n",
       " ['d7083f5e1d50c264277d624340edaaf3dc16095b', 'SOUVUHC12A67020E3B', '1'],\n",
       " ['d7083f5e1d50c264277d624340edaaf3dc16095b', 'SOUQERE12A58A75633', '1'],\n",
       " ['d7083f5e1d50c264277d624340edaaf3dc16095b', 'SOIPJAX12A8C141A2D', '1'],\n",
       " ['d7083f5e1d50c264277d624340edaaf3dc16095b', 'SOEFCDJ12AB0185FA0', '2']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as psf\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "triplet_rdd=sc.parallelize(triplet_rdd.take(10000))\n",
    "triplet_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d7083f5e1d50c264277d624340edaaf3dc16095b',\n",
       "  'SOUVUHC12A67020E3B,SOUQERE12A58A75633,SOIPJAX12A8C141A2D,SOEFCDJ12AB0185FA0,SOEFCDJ12AB0185FA0,SOATCSU12A8C13393A,SOZPZGN12A8C135B45,SOPFVWP12A6D4FC636,SOHEKND12A8AE481D0,SOPSVVG12A8C13B444,SODSKZZ12AB0188524,SONZTNP12A8C1321DF,SOVVLKF12A8C1424F0,SOMLKZO12AB017F4AE,SOACRJG12A8C137A8D,SONJVYU12A8AE44F9E,SOSOUKN12A8C13AB79'),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  'SOFRQTD12A81C233C0,SOZQIUZ12A8C13CFBE,SOKQNYH12A6D4FA5D3,SOQDMED12A67ADE731,SOAXGDH12A8C13F8A1,SOAAGFH12A8C13D072')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step1: Compute cosine similarity between all pairs of users.\n",
    "#We are multipying the second column with the third that means song-id, no of times the song was played.\n",
    "#For example if a UserID: 'fdf6afb5daefb42774617cf223475c6013969724' SongID: 'SOYPQYA12A6D4FB8F4’ Times played: ‘3’\n",
    "#then it will be Column 1: User id,Column 2: list of songs then applying the reduced by key.\n",
    "#Now all the songs listened by the user are present in a single row in the temp RDD.\n",
    "X = triplet_rdd.map(lambda z: (z[0],((z[1]+',')*int(z[2]))[:-1]))\n",
    "temp = X.reduceByKey(lambda a, v: a + \",\" + v)\n",
    "temp.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User_id='d7083f5e1d50c264277d624340edaaf3dc16095b', Songs=['SOUVUHC12A67020E3B', 'SOUQERE12A58A75633', 'SOIPJAX12A8C141A2D', 'SOEFCDJ12AB0185FA0', 'SOEFCDJ12AB0185FA0', 'SOATCSU12A8C13393A', 'SOZPZGN12A8C135B45', 'SOPFVWP12A6D4FC636', 'SOHEKND12A8AE481D0', 'SOPSVVG12A8C13B444', 'SODSKZZ12AB0188524', 'SONZTNP12A8C1321DF', 'SOVVLKF12A8C1424F0', 'SOMLKZO12AB017F4AE', 'SOACRJG12A8C137A8D', 'SONJVYU12A8AE44F9E', 'SOSOUKN12A8C13AB79']),\n",
       " Row(User_id='d68dc6fc25248234590d7668a11e3335534ae4b4', Songs=['SOFRQTD12A81C233C0', 'SOZQIUZ12A8C13CFBE', 'SOKQNYH12A6D4FA5D3', 'SOQDMED12A67ADE731', 'SOAXGDH12A8C13F8A1', 'SOAAGFH12A8C13D072'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are converting the temp RDD into Spark DataFrame by importing toDF, which has 2 columns i.e user id and Songs.\n",
    "hasattr(temp, \"toDF\")\n",
    "Data_frame = temp.toDF([\"User_id\", \"Songs\"]).withColumn(\"Songs\", psf.split(psf.regexp_replace(\"Songs\", \" \", \"\"), ','))\n",
    "Data_frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "#Term frequency TF(t,d) is the number of times that term t appears in document d \n",
    "#while document frequency DF(t,D) is the number of documents that contains term t.\n",
    "#When applying HashingTF we need only needs a single pass to the data and stored it in \"term_frequency\"\n",
    "#while applying IDF needs two passes: first to compute the IDF vector \n",
    "#and second to scale the term frequencies by IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User_id='d7083f5e1d50c264277d624340edaaf3dc16095b', Songs=['SOUVUHC12A67020E3B', 'SOUQERE12A58A75633', 'SOIPJAX12A8C141A2D', 'SOEFCDJ12AB0185FA0', 'SOEFCDJ12AB0185FA0', 'SOATCSU12A8C13393A', 'SOZPZGN12A8C135B45', 'SOPFVWP12A6D4FC636', 'SOHEKND12A8AE481D0', 'SOPSVVG12A8C13B444', 'SODSKZZ12AB0188524', 'SONZTNP12A8C1321DF', 'SOVVLKF12A8C1424F0', 'SOMLKZO12AB017F4AE', 'SOACRJG12A8C137A8D', 'SONJVYU12A8AE44F9E', 'SOSOUKN12A8C13AB79'], term_frequency=SparseVector(262144, {5585: 1.0, 33749: 1.0, 50952: 1.0, 52168: 1.0, 53458: 1.0, 63492: 1.0, 77828: 1.0, 86816: 1.0, 94885: 2.0, 103956: 1.0, 112693: 1.0, 170827: 1.0, 214706: 1.0, 229499: 1.0, 230458: 1.0, 234410: 1.0}), feature=SparseVector(262144, {5585: 5.2444, 33749: 5.2444, 50952: 5.2444, 52168: 5.2444, 53458: 4.1458, 63492: 5.2444, 77828: 5.2444, 86816: 5.2444, 94885: 10.4888, 103956: 5.2444, 112693: 4.8389, 170827: 5.2444, 214706: 5.2444, 229499: 5.2444, 230458: 5.2444, 234410: 5.2444})),\n",
       " Row(User_id='d68dc6fc25248234590d7668a11e3335534ae4b4', Songs=['SOFRQTD12A81C233C0', 'SOZQIUZ12A8C13CFBE', 'SOKQNYH12A6D4FA5D3', 'SOQDMED12A67ADE731', 'SOAXGDH12A8C13F8A1', 'SOAAGFH12A8C13D072'], term_frequency=SparseVector(262144, {58515: 1.0, 73349: 1.0, 120367: 1.0, 174579: 1.0, 190153: 1.0, 203106: 1.0}), feature=SparseVector(262144, {58515: 3.2295, 73349: 4.8389, 120367: 5.2444, 174579: 5.2444, 190153: 2.9418, 203106: 5.2444}))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Next we took the Hashing term frequency (TF) and stored it as ‘tf’ \n",
    "### We took the inverse document(IDF) frequency of the DataFrame and stored it as ‘tfidf’.\n",
    "#Term frequency TF(t,d) is the number of times that term t appears in document d, \n",
    "#while document frequency DF(t,D) is the number of documents that contains term t.\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"Songs\", outputCol=\"term_frequency\")\n",
    "term_frequency = hashingTF.transform(Data_frame)\n",
    "idf = IDF(inputCol=\"term_frequency\", outputCol=\"feature\").fit(term_frequency)\n",
    "tfidf = idf.transform(term_frequency)\n",
    "tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User_id='d7083f5e1d50c264277d624340edaaf3dc16095b', Songs=['SOUVUHC12A67020E3B', 'SOUQERE12A58A75633', 'SOIPJAX12A8C141A2D', 'SOEFCDJ12AB0185FA0', 'SOEFCDJ12AB0185FA0', 'SOATCSU12A8C13393A', 'SOZPZGN12A8C135B45', 'SOPFVWP12A6D4FC636', 'SOHEKND12A8AE481D0', 'SOPSVVG12A8C13B444', 'SODSKZZ12AB0188524', 'SONZTNP12A8C1321DF', 'SOVVLKF12A8C1424F0', 'SOMLKZO12AB017F4AE', 'SOACRJG12A8C137A8D', 'SONJVYU12A8AE44F9E', 'SOSOUKN12A8C13AB79'], term_frequency=SparseVector(262144, {5585: 1.0, 33749: 1.0, 50952: 1.0, 52168: 1.0, 53458: 1.0, 63492: 1.0, 77828: 1.0, 86816: 1.0, 94885: 2.0, 103956: 1.0, 112693: 1.0, 170827: 1.0, 214706: 1.0, 229499: 1.0, 230458: 1.0, 234410: 1.0}), feature=SparseVector(262144, {5585: 5.2444, 33749: 5.2444, 50952: 5.2444, 52168: 5.2444, 53458: 4.1458, 63492: 5.2444, 77828: 5.2444, 86816: 5.2444, 94885: 10.4888, 103956: 5.2444, 112693: 4.8389, 170827: 5.2444, 214706: 5.2444, 229499: 5.2444, 230458: 5.2444, 234410: 5.2444}), normalized=SparseVector(262144, {5585: 0.2326, 33749: 0.2326, 50952: 0.2326, 52168: 0.2326, 53458: 0.1839, 63492: 0.2326, 77828: 0.2326, 86816: 0.2326, 94885: 0.4653, 103956: 0.2326, 112693: 0.2147, 170827: 0.2326, 214706: 0.2326, 229499: 0.2326, 230458: 0.2326, 234410: 0.2326})),\n",
       " Row(User_id='d68dc6fc25248234590d7668a11e3335534ae4b4', Songs=['SOFRQTD12A81C233C0', 'SOZQIUZ12A8C13CFBE', 'SOKQNYH12A6D4FA5D3', 'SOQDMED12A67ADE731', 'SOAXGDH12A8C13F8A1', 'SOAAGFH12A8C13D072'], term_frequency=SparseVector(262144, {58515: 1.0, 73349: 1.0, 120367: 1.0, 174579: 1.0, 190153: 1.0, 203106: 1.0}), feature=SparseVector(262144, {58515: 3.2295, 73349: 4.8389, 120367: 5.2444, 174579: 5.2444, 190153: 2.9418, 203106: 5.2444}), normalized=SparseVector(262144, {58515: 0.2888, 73349: 0.4328, 120367: 0.4691, 174579: 0.4691, 190153: 0.2631, 203106: 0.4691}))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we are using Normalizer function we are performing L2 normalized for the entire ‘tfidf’ \n",
    "# and stored it as ‘normalizer_data’. Normalizer produce a transformed Vector on an RDD[Vector]\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"feature\", outputCol=\"normalized\")\n",
    "normalizer_data = normalizer.transform(tfidf)\n",
    "normalizer_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User1='53f02466e42999daf6ab54b38a532b5435024f22', User2='eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', Cosine_Similarity=0.6664200920551405),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', Cosine_Similarity=0.5739153330964452),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='a344d1f94e0f6d5783860f62d8bc8ba2fec3d530', Cosine_Similarity=0.5545182603991983),\n",
       " Row(User1='62eb207ebff66e00a42ab80b06e0e3a2a2c13554', User2='8c9f3dd16c120e68bdd1dd34bfb7c5fd3d6dc487', Cosine_Similarity=0.5543085145384308),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='53f02466e42999daf6ab54b38a532b5435024f22', Cosine_Similarity=0.5426874103603517),\n",
       " Row(User1='07260aa795b86382fbddea37b7b8f6f7d5a1db0a', User2='bcb1e6d620cf522390d5c92bae26936928e0b588', Cosine_Similarity=0.5295798772858137),\n",
       " Row(User1='3a151b699ce726e1cff56a5bb069aec50efcba45', User2='fbcafcd35212137638b34ce4d78981b994e2aefa', Cosine_Similarity=0.5095908880845609),\n",
       " Row(User1='a344d1f94e0f6d5783860f62d8bc8ba2fec3d530', User2='c732f882aa8d6db3bfaf8037d6418f27d3e07fc8', Cosine_Similarity=0.4994277270188659),\n",
       " Row(User1='7b104f995943ca5f5df3d6b71aba712cd6e81632', User2='9d6aec26a2b0e0f10a58fe2ab64190263c2585ca', Cosine_Similarity=0.4384438636975086),\n",
       " Row(User1='b6fe63bd640050b922bda5e4ec36d110b878be8a', User2='bcb1e6d620cf522390d5c92bae26936928e0b588', Cosine_Similarity=0.42033404612668734)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The cosine similarity of the vectors is the dot product of two L2 normalized TF-IDF vectors, result is stored \n",
    "#in ‘final_result’ DataFrame which has three columns User1, User2 and Cosine_Similarity. \n",
    "\n",
    "dot_product = psf.udf(lambda a,b: float(a.dot(b)), DoubleType())\n",
    "temp  = normalizer_data.alias(\"a\").join(normalizer_data.alias(\"b\"), psf.col(\"a.User_id\") < psf.col(\"b.User_id\"))\n",
    "final_result = temp.select(psf.col(\"a.User_id\").alias(\"User1\"),psf.col(\"b.User_id\").alias(\"User2\"), \n",
    "                dot_product(\"a.normalized\", \"b.normalized\").alias(\"Cosine_Similarity\")).sort(desc(\"Cosine_Similarity\"))\n",
    "\n",
    "final_result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User1='53f02466e42999daf6ab54b38a532b5435024f22', User2='eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', Cosine_Similarity=0.6664200920551405),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', Cosine_Similarity=0.5739153330964452),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='a344d1f94e0f6d5783860f62d8bc8ba2fec3d530', Cosine_Similarity=0.5545182603991983),\n",
       " Row(User1='62eb207ebff66e00a42ab80b06e0e3a2a2c13554', User2='8c9f3dd16c120e68bdd1dd34bfb7c5fd3d6dc487', Cosine_Similarity=0.5543085145384308),\n",
       " Row(User1='00f7c493ee64884998ea98d9f5bed87bc4a0afcf', User2='53f02466e42999daf6ab54b38a532b5435024f22', Cosine_Similarity=0.5426874103603517)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2:Sort the similarity score and print the top-5 similar users. For which we are sorting the Cosine_Similarity \n",
    "#final_result and top 5 are displayed. \n",
    "\n",
    "resultt = final_result.sort(desc(\"Cosine_Similarity\"))\n",
    "resultt.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('53f02466e42999daf6ab54b38a532b5435024f22',\n",
       "  ('eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', 0.6664200920551405)),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  ('eb3bfe7f67fb59d4427cca56932a4d83caaaaa76', 0.5739153330964452)),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  ('a344d1f94e0f6d5783860f62d8bc8ba2fec3d530', 0.5545182603991983)),\n",
       " ('62eb207ebff66e00a42ab80b06e0e3a2a2c13554',\n",
       "  ('8c9f3dd16c120e68bdd1dd34bfb7c5fd3d6dc487', 0.5543085145384308)),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  ('53f02466e42999daf6ab54b38a532b5435024f22', 0.5426874103603517))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 3: If the top-5 user set has an user appearing more than once, \n",
    "#ignore that pair and take the next best pair from the sorted list.\n",
    "\n",
    "# Now we are converting the dataframe into rdd and rearranging it into key value pairs\n",
    "temp = resultt\n",
    "final_result_rdd = temp.rdd\n",
    "final_result_rdd = final_result_rdd.map(lambda z: (z[0],(z[1],z[2])))\n",
    "final_result_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eb3bfe7f67fb59d4427cca56932a4d83caaaaa76',\n",
       "  ('53f02466e42999daf6ab54b38a532b5435024f22', 0.6664200920551405)),\n",
       " ('bcb1e6d620cf522390d5c92bae26936928e0b588',\n",
       "  ('3d28488a659d1cacc598d17074b233985271c65e', 0.304061936030354)),\n",
       " ('d8c425c171d9d67dc33240f605f6beed96e5e6ff',\n",
       "  ('18ce1da0e1017e31baaa5f80afa64ee3c7fab379', 0.29226509591111255)),\n",
       " ('ef0d21935a2f8ae90571dbfab800f87fa5b38769',\n",
       "  ('6e6b836e0a82b8d77865041d83f6b35bcc491f36', 0.22141713324973636)),\n",
       " ('8061f61372876878c2d67bc49b3ddbd2c83d69e2',\n",
       "  ('0c65a060faaf2c3f9a6aed6c9732131709c33d55', 0.20766124966037036))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying reduceByKey to final_result_rdd and added all the values. We have selected the first value \n",
    "#from the reduceByKey result using map, so that we will be eliminating the duplicate values. \n",
    "# Note : User1, (User2,Rating) --> resembles our final_result_rdd , To this we are applying map transform function to swap\n",
    "# the User1 and User2 column i.e User2, (User1,Rating) \n",
    "\n",
    "user_1 = final_result_rdd.reduceByKey(lambda a,v:a+v).map(lambda z: (z[1][0],(z[0],z[1][1])))\n",
    "user_1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating the same above step and obtaining distinct User2 values. \n",
    "# values in user_2 are saved in user_2_list \n",
    "user_2 = user_1.reduceByKey(lambda a,v:a+v).map(lambda z: (z[0],z[1][0],z[1][1]))\n",
    "user_2_list = user_2.map(lambda z:z[0]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eb3bfe7f67fb59d4427cca56932a4d83caaaaa76',\n",
       "  '53f02466e42999daf6ab54b38a532b5435024f22',\n",
       "  0.6664200920551405),\n",
       " ('fbcafcd35212137638b34ce4d78981b994e2aefa',\n",
       "  '3a151b699ce726e1cff56a5bb069aec50efcba45',\n",
       "  0.5095908880845609),\n",
       " ('9d6aec26a2b0e0f10a58fe2ab64190263c2585ca',\n",
       "  '7b104f995943ca5f5df3d6b71aba712cd6e81632',\n",
       "  0.4384438636975086),\n",
       " ('c34670d9c1718361feb93068a853cead3c95b76a',\n",
       "  '49bf7109eba57fa27b82242ba8e058e4f57d71c4',\n",
       "  0.40097671623245884),\n",
       " ('773afdd8317e10701e81008881e78e6966f031d9',\n",
       "  '42a9daa28f605e4f269711946cdbe0498a172706',\n",
       "  0.3325825924802534)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are verifying whether our user present in the column User1 is unique from all users in the \n",
    "#user_2_list list and sorted by Cosine similarity values\n",
    "final_result = user_2.filter(lambda z:z[1] not in user_2_list).sortBy(lambda z:-float(z[2]))\n",
    "# Cosine similarity top 5 pairs.\n",
    "final_result.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('53f02466e42999daf6ab54b38a532b5435024f22',\n",
       "  'eb3bfe7f67fb59d4427cca56932a4d83caaaaa76',\n",
       "  0.6664200920551405),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  'eb3bfe7f67fb59d4427cca56932a4d83caaaaa76',\n",
       "  0.5739153330964452),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  'a344d1f94e0f6d5783860f62d8bc8ba2fec3d530',\n",
       "  0.5545182603991983),\n",
       " ('62eb207ebff66e00a42ab80b06e0e3a2a2c13554',\n",
       "  '8c9f3dd16c120e68bdd1dd34bfb7c5fd3d6dc487',\n",
       "  0.5543085145384308),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  '53f02466e42999daf6ab54b38a532b5435024f22',\n",
       "  0.5426874103603517)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part 4 : For a given user_id, identify the top-5 similar users and \n",
    "# hence song recommendations from other user's list.\n",
    "\n",
    "# Now we are converting the dataframe 'final_result' obtained in part 2 in step 4 into rdd and rearranging it.\n",
    "final = resultt \n",
    "final_rdd = final.rdd\n",
    "final_rdd=final_rdd.map(lambda z: (z[0],z[1],z[2]))\n",
    "final_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6493c305190b52657d4ea3f4adf367ffcf3427af',\n",
       "  'a344d1f94e0f6d5783860f62d8bc8ba2fec3d530',\n",
       "  0.035400549259528534),\n",
       " ('6493c305190b52657d4ea3f4adf367ffcf3427af',\n",
       "  'c732f882aa8d6db3bfaf8037d6418f27d3e07fc8',\n",
       "  0.030611838009092972),\n",
       " ('00f7c493ee64884998ea98d9f5bed87bc4a0afcf',\n",
       "  '6493c305190b52657d4ea3f4adf367ffcf3427af',\n",
       "  0.025400266694165983),\n",
       " ('36a35718d262b62cf00f038d76c4920912501b8a',\n",
       "  '6493c305190b52657d4ea3f4adf367ffcf3427af',\n",
       "  0.020937179591105817),\n",
       " ('6493c305190b52657d4ea3f4adf367ffcf3427af',\n",
       "  'a5d92e23cf3f711dfc473f1c3b296492ec02effd',\n",
       "  0.018188662563497538)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are considering a user_id for instance, then getting all the rows from 'final_RDD' where user id is \n",
    "#either User1 or User2.We are storing the result in 'similar_users' and extracting the top 5 users.\n",
    "\n",
    "user_id=\"6493c305190b52657d4ea3f4adf367ffcf3427af\"\n",
    "\n",
    "similar_users=final_rdd.filter(lambda z: (z[0]==user_id or z[1]==user_id))\n",
    "similar_users.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a344d1f94e0f6d5783860f62d8bc8ba2fec3d530', 0.035400549259528534),\n",
       " ('c732f882aa8d6db3bfaf8037d6418f27d3e07fc8', 0.030611838009092972),\n",
       " ('a5d92e23cf3f711dfc473f1c3b296492ec02effd', 0.018188662563497538),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4', 0.01608824411530434),\n",
       " ('bdbf8ddd82fa83ef4538a15298dfca19bfc4a3ca', 0.013944172374947189),\n",
       " ('acbc046380b5b7bb4c3bdb4f2acd2bda76f31553', 0.013358874628789546),\n",
       " ('c759e740af57c477fe358e62ad7b3b1f2f113a2f', 0.009018871203308977),\n",
       " ('c1b38ae42a5c3846a2d7bffb107729c561f57da0', 0.008515212434300503),\n",
       " ('c5a705e3d17dfd5d8322ac5ec2a534469794bd7e', 0.00799113658452152),\n",
       " ('97507276e3739cc868d2b29d06eb3605cfb9b583', 0.007713955812924308)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If our considered user_id is present in User1 column, then we need to get the User2 column and Cosine Similarity.\n",
    "# and save the value in 'a'. If our considered user_id is present in User2 column, then we need to get the User1 column and Cosine Similarity.\n",
    "# and save the value in 'b' then performing union of 'x' and 'y'.\n",
    "\n",
    "a = similar_users.filter(lambda z: z[0]==user_id).map(lambda z: (z[1],z[2]))\n",
    "b = similar_users.filter(lambda z: z[1]==user_id).map(lambda z: (z[0],z[2]))\n",
    "similar = a.union(b).map(lambda z: (z))\n",
    "similar.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOFRQTD12A81C233C0', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOZQIUZ12A8C13CFBE', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOKQNYH12A6D4FA5D3', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOQDMED12A67ADE731', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOAXGDH12A8C13F8A1', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('d68dc6fc25248234590d7668a11e3335534ae4b4',\n",
       "  (('SOAAGFH12A8C13D072', 0.0021624707525830715), 0.01608824411530434)),\n",
       " ('6530c4fc41b9110de5d39fe0355fa103c66385f0',\n",
       "  (('SOCHADN12A6310ED94', 0.010812353762915358), 0.0)),\n",
       " ('6530c4fc41b9110de5d39fe0355fa103c66385f0',\n",
       "  (('SOXVVSM12A8C142224', 0.0021624707525830715), 0.0)),\n",
       " ('6530c4fc41b9110de5d39fe0355fa103c66385f0',\n",
       "  (('SOQLUTQ12A8AE48037', 0.0021624707525830715), 0.0)),\n",
       " ('6530c4fc41b9110de5d39fe0355fa103c66385f0',\n",
       "  (('SOWEJXA12A6701C574', 0.010812353762915358), 0.0))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Step 3, we are getting the triplet_rdd which has users, songs, Rating and stored in 'Final' and applied \n",
    "#map to re-arrange key, value pairs. Now we are joining this with 'similar' to obtain top 5 similar users.\n",
    "\n",
    "Final = triplet_rdd.map(lambda z: (z[0],z[1],(int(z[2])/total)*10000)).map(lambda z: (z[0],(z[1],z[2])))\n",
    "result=Final.join(similar)\n",
    "result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOJSXJY12A8C13E32E', 0.2703088440728839),\n",
       " ('SOTWNDJ12A8C143984', 0.19245989697989332),\n",
       " ('SOAKBZX12AB017C912', 0.17083518945406262),\n",
       " ('SOFGJCW12AF72A812D', 0.1578603649385642),\n",
       " ('SOMUGJA12A67020841', 0.151372952680815)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying map transformation to 'result' to get only the songs recommendation from other user's list \n",
    "# and Rating and sort it in descending order. Thus we are getting top-5 similar users and recommendations.\n",
    "\n",
    "top_similar_users=result.map(lambda z: (z[1][0][0],z[1][0][1])).sortBy(lambda z: -z[1])\n",
    "top_similar_users.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
